import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import (accuracy_score, recall_score, precision_score,
                             f1_score, jaccard_score, confusion_matrix, roc_curve, auc)

# Load dataset
df = pd.read_csv(r"samples_cancer.csv")

# Convert 'BareNuc' to numeric, replacing '?' with NaN
df['BareNuc'] = pd.to_numeric(df['BareNuc'], errors='coerce')

# Drop rows with missing values
df.dropna(inplace=True)

# Drop 'ID' column if it exists
df.drop(columns=['ID'], inplace=True, errors='ignore')

# Splitting data into features and target
X = df.drop(columns=['Class'])
y = df['Class'].replace({2: 0, 4: 1})  # 2: Benign (0), 4: Malignant (1)

# Train-test split (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define SVM kernels
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
svm_results = {}

# Train and evaluate SVM models with different kernels
for kernel in kernels:
    model = SVC(kernel=kernel, probability=True, random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_prob = model.predict_proba(X_test_scaled)[:, 1]

    # Compute metrics
    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    jaccard = jaccard_score(y_test, y_pred)
    error_rate = 1 - accuracy
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Store results
    svm_results[kernel] = {
        "accuracy": accuracy, "recall": recall, "precision": precision, "f1_score": f1,
        "jaccard": jaccard, "error_rate": error_rate, "confusion_matrix": conf_matrix, "y_prob": y_prob
    }

# Plot ROC curves for all SVM models
plt.figure(figsize=(10, 7))
for kernel in kernels:
    fpr, tpr, _ = roc_curve(y_test, svm_results[kernel]["y_prob"])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{kernel.capitalize()} (AUC = {roc_auc:.2f})")

# Plot baseline
plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison of SVM Kernels")
plt.legend()
plt.show()

# Print results
for kernel, metrics in svm_results.items():
    print(f"\nKernel: {kernel.capitalize()}")
    print(f"Accuracy: {metrics['accuracy']:.2f}")
    print(f"Recall: {metrics['recall']:.2f}")
    print(f"Precision: {metrics['precision']:.2f}")
    print(f"F1 Score: {metrics['f1_score']:.2f}")
    print(f"Jaccard Score: {metrics['jaccard']:.2f}")
    print(f"Error Rate: {metrics['error_rate']:.2f}")
    print(f"Confusion Matrix:\n{metrics['confusion_matrix']}")
